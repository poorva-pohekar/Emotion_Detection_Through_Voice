# Emotion_Detection_Through_Voice

This project detects human emotions (e.g., happy, sad, angry) from voice recordings using machine learning. It uses the RAVDESS dataset and supports both real-time recording and audio file uploads through a clean Streamlit web interface.

---

## ğŸ“Œ Features

- ğŸ¤ Record voice or upload `.wav/.mp3` files
- ğŸ” Extract audio features (MFCC, Chroma, Mel, Contrast, Tonnetz)
- ğŸ“Š Preprocessing with StandardScaler + PCA
- âš–ï¸ Handles class imbalance using SMOTE
- ğŸ§  Emotion classification using XGBoost
- ğŸ“ˆ Real-time prediction with visualization (Mel Spectrogram)
- ğŸ§ª 8 emotion classes: Neutral, Calm, Happy, Sad, Angry, Fearful, Disgust, Surprised

---

## ğŸ—‚ï¸ Project Structure

emotion_detection/
â”œâ”€â”€ data_preprocessing.py # Feature extraction and dataset loading
â”œâ”€â”€ train_model.py # Train and save XGBoost classifier
â”œâ”€â”€ streamlit_app.py # Frontend app for prediction
â”œâ”€â”€ model_utils.py # Helper to load model, scaler, PCA
â”œâ”€â”€ recorder.py # Records audio via microphone
â”œâ”€â”€ saved_model/ # Stores .pkl files for model, scaler, PCA
â”œâ”€â”€ ravdess-dataset/ #  RAVDESS audio dataset
â””â”€â”€ README.md